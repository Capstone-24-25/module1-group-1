---
title: "Biomarkers of ASD"
subtitle: "If you want a subtitle put it here"
author: "List names here"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

Use this as a template. Keep the headers and remove all other text. In all, your report can be quite short. When it is complete, render and then push changes to your team repository.

```{r}
# load any other packages and read data here
library(tidyverse)
```

## Abstract

For this project, we looked at data from Hewitson *et al.* (2021). *Blood biomarker discovery for autism spectrum disorder: A proteomic analysis.* In this study, they wanted to see if there were differences in the levels of various of proteins between young boys who were in the autism spectrum and those who were typically developing. A total of 1125 proteins were analyzed through various machine learning methods to see which proteins could be identified as blood bio-markers for autism spectrum disorder. For our project, we wanted to look deeper into these different methodologies. We aimed to explore the sensitivity of the results of the different design choices. In order to do this, we first looked further into how outliers affect the overall result and what we can do to minimize their effects. Then, we modified the various methods -- T-test, logistical regression, and random forest -- to test their accuracy and tested if other methods could further improve accuracy.

## Dataset

Write a brief data description, including: how data were obtained; sample characteristics; variables measured; and data preprocessing. This can be largely based on the source paper and should not exceed 1-2 paragraphs.

Data for this project was obtained from *Blood biomarker discovery for autism spectrum disorder: A proteomic analysis.* Their study

## Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

We began with a simple exploratory data analysis and data preprocessing. In the raw data, we notice there are a high amount of outliers and the data is fairly skewed for each protein. To remove the skew, we performed a log transformation as well as normalization by centering and scaling all values. To prevent outliers from drastically impacting our analysis, we trimmed outliers to have a value of -3 or 3 depending on their position. Next, we conducted a more in-depth analysis to determine whether the presence of outliers can be explained by any other variables. First, we identified subjects with extremely high outlier count to check for any patterns. To see whether group affects outlier count, we compare the mean and median outlier counts between TD and ASD subjects. Finally, we checked to see if there is correlation between ADOS score and outlier count. Ultimately, we did not find any logical explanation for the outliers.

For the second part of our analysis, we examine whether different methodologies for protein selection will result in better model performance. The first methodology change involves using a train-test split, where 80% of the data is used for model training and the other 20% for testing accuracy. This resulted in a 0.774 accuracy, which is worse than the original analysis. Next, we increased the number of proteins to be chosen during the selection process. The original method used the top 10 proteins from each procedure, and we tried selecting anywhere from 11-30 proteins. We found that selecting more proteins tends to increase accuracy up to 0.96 at 26 proteins, after which accuracy begins to drop off. Finally, we tested out a fuzzy intersection when determining the best combination of proteins across all selection methods. This method generates a panel of 10 proteins(DERM" "IgD" "TSP4" "MRC2" "PTN" "FSTL1" "MAPK14" "TPSG1" "SRCN1" "SOST") but does not significantly improve accuracy.

## Findings

Summarize your findings here. I've included some subheaders in a way that seems natural to me; you can structure this section however you like.

### Impact of preprocessing and outliers

**Task 1:** The main reason for log-transforming the protein levels in biomarker-raw.csv is to ensure that the model is linear. It helps to reduce the skew of the data which in turn helps handle outliers. This allows for the analysis to be simpler. Log-transformation compresses the data which can be seen in the preprocessing script. This will ideally make visualizing the distributions of the various proteins simpler and reduce any outliers that may be present. Looking at the raw distributions for the sample of proteins, we can see that the values are much larger than in the log-transformation version.

**Task 2:** The mean outlier count among all 154 subjects was roughly 15.45. There were some outlier subjects that had an exceedingly high number of outliers, in particular 7 subjects with over 50. Of these outlier subjects, 5 of them were from the TD group while 2 of them were from the ASD group. The mean outlier count for the entire ASD group was 13.25, compared to 17.59 in the TD group. Therefore, it appears that subjects in the TD group tend to have more frequent outliers. Considering there are over 1300 proteins in the dataset, this difference does not seem significant. This difference can be explained by the greater presence of outlier subjects in the TD group, which skews the value of the mean upward. If we look at the median, which is less impacted by outliers, both groups have the exact same median count of 8.5.

We were also curious to examine whether ADOS score had any correlation with the outlier count of ASD subjects. Visually, there does not appear to be any relationship between these 2 variables. Since outlier count by subject is not dependent on group or ADOS score, we conclude that the presence of outliers is completely random.

### Methodlogical variations

**Task 3:**

We carried out the entire selection procedure on a training partition, and tested the final model on the testing set. The results show that the model has a predictive accuracy of 0.774, which is lower than the in-class analysis where the selection procedure is carried out on the entire data set.

First, we tried to split the data set into $80\%$ training set and $20\%$ validation set. Then we tried for different numbers of top predictive proteins using each selection method to train our model. For 10-30 numbers of proteins, the accuracy increases with the number of proteins until the accuracy starts to decrease after the number of proteins is 26. When we pick 26 top predictive proteins, we can get a $96\%$ accuracy on the validation set.

Then, we also explored using a fuzzy intersection instead of a hard intersection to combine the sets of top predictive proteins across selection methods. We did this through the stringdist_inner_join function in the "fuzzyjoin" package, using the Jaro-Winkler similarity scores. After tuning we decided that the best maximum allowed distance for the fuzzy intersection is around 0.46, which produced an intersection with 10 proteins "DERM" "IgD" "TSP4" "MRC2" "PTN" "FSTL1" "MAPK14" "TPSG1" "SRCN1" "SOST", instead of the 6 protein hard intersection. However, the logistic regression shows that this panel of proteins does not significantly improve the prediction accuracy.

### Improved classifier

**Task 4:**

Our second attempt was to use 20 top proteins for each method and used a different intersection method. We used take the hard intersection of the 20 top proteins from each and then removed any protein that is not in the top 10 predictive proteins for each method. This gives us a 5-protein panel: "DERM" "IgD" "TSP4" "PTN" "FSTL1", which achieved a better accuracy. The accuracy for the in-class analysis was 0.774 and this panel achieved an accuracy of 0.839.
